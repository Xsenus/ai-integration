# Пайплайн обработки клиентов

Документ описывает маршруты `/v1/pipeline/full` и `/v1/pipeline/auto`, которые запускают последовательную обработку ИНН с использованием всех подсервисов (`lookup`, `parse-site`, `analyze-json`, `ib-match`, `equipment-selection`).

## `/v1/pipeline/full`

* **Запрос:** `POST` с телом `{ "inn": "7700000000" }`. Дополнительные поля запроса отсутствуют — все параметры берутся из стандартных настроек сервисов.
* **Шаги выполнения:**
  1. `lookup_card` — подтягивает карточку компании и сохраняет её в `bitrix_data`/`parsing_data`.
  2. `parse_site` — собирает домены, скачивает главные страницы, формирует описание и embedding, обновляет `pars_site`.
  3. `analyze_json` — отправляет свежие снапшоты и каталоги во внешний AI‑сервис, применяет `db_payload` к `ai_site_*`.
  4. `ib_match` — сравнивает embedding сайта с каталогом `ib_prodclass` и сохраняет `prodclass`.
  5. `equipment_selection` — рассчитывает набор оборудования по последней записи клиента в `clients_requests` и выбирает стратегию источника (`site` или `okved`) на основе `description_okved_score`/`okved_score` и `prodclass_by_okved` (порог настраивается через `EQUIPMENT_SELECTION_OKVED_THRESHOLD`).
* **Обработка ошибок:** каждая стадия логируется отдельной записью. Ошибки на фатальных шагах (`lookup`) прекращают пайплайн; остальные фиксируются в массиве `errors`, но ответ всё равно возвращается.
* **Ответ:** модель `PipelineFullResponse` содержит результаты каждого шага (или `null`, если шаг пропущен), список ошибок с `status_code`/`detail` и `duration_ms` — общее время выполнения.

## `/v1/pipeline/auto`

* **Запрос:** `POST` без тела. Эндпоинт находит кандидатов автоматически:
  * выбирает до 200 последних `DaDataResult`;
  * ищет для них свежие `clients_requests` и проверяет, есть ли `pars_site`, `ai_site_goods_types`, `ai_site_equipment` и расчёт оборудования;
  * фильтрует только ИНН без готового `equipment_selection` и запускает до 5 пайплайнов подряд.
* **Ответ:** `PipelineAutoResponse` с:
  * `processed` — список `PipelineAutoResult`, где хранится статус кандидата и полный ответ пайплайна или описание ошибки;
  * `skipped` — кандидаты, которые не попали в лимит обработки.
* **Поведение по БД:** требуется активный `postgres` (для чтения витрин) и `bitrix_data` (для сессии `lookup`/`parse-site`). Ошибки чтения справочных таблиц учитываются и не блокируют остальные операции.

## Что записывается в логах и базах

* В начале и конце каждого шага выводится идентификатор ИНН, длительность и исход ошибки (HTTP‑статус или текст исключения).
* `parse_site` гарантирует наличие `clients_requests` (предварительный upsert до парсинга доменов), поэтому при сценарии «сайт недоступен» downstream‑шаги получают валидный `company_id`.
* `parse_site` обновляет `pars_site` сразу в двух базах, чтобы downstream‑сервисы видели одинаковые данные.
* `analyze_json` записывает «сырые» ответы внешнего сервиса, обрезанные версии для логов и применённые `db_payload` (количество сохранённых товаров/оборудования и итоговый `prodclass`).
* `ib_match` и `equipment_selection` пишут результаты только в `postgres`, поэтому при отсутствии DSN расчёт будет пропущен и отражён в `errors`.

Используйте этот документ как обзор для координации команд: он показывает, какие шаги идут в каком порядке, что требуется от инфраструктуры и где искать результаты при расследовании ошибок.

## Изменения по устойчивости (2026-02)

* `lookup/card` теперь синхронизирует `clients_requests` не только при refresh из DaData, но и при отдаче карточки из локального кеша.
* `ib-match/by-inn` не падает в 500, если в целевой БД отсутствует схема/таблица `parsing_data.clients_requests`: ошибка fallback-запроса логируется, а клиент получает корректный `404`, если запись не найдена.
* Таблицы `EQUIPMENT_*` синхронизируются изолированно по компании: ключ `(company_id, id)` и предварительная очистка строк текущей компании перед вставкой актуального среза. Это исключает перетирание данных между компаниями и «хвосты» от прошлых прогонов.
