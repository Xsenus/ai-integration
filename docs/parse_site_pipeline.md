# Поток обработки `/v1/parse-site`

Документ описывает, какие данные мы отправляем на анализ сайта, как формируется описание и embedding, каким образом вычисляется сходство с ОКВЭД и что возвращает API.

## 1. Сбор и нормализация доменов
* Получаем домены из ручного ввода, e-mail и внутренних БД (`clients_requests`, `ib_clients`, `dadata_result`).
* Все кандидаты приводятся к нормализованному виду без `www.` и дубликатов.
* Для каждого домена формируется задача `_fetch_domain_parallel`, которая скачивает главную страницу и нарезает текст на чанки.

## 2. Формирование текста и описание сайта
* Чанки склеиваются в `full_text`. Если текст пустой, домен считается разобранным без описания.
* Если текст есть, вызываем `fetch_site_description`, передавая весь `full_text`. Ответ содержит описание и при наличии — готовый embedding.
* При отсутствии embedding выполняем повторный вызов `fetch_embedding`, чтобы сохранить вектор в `pars_site.text_vector`.
* Обновление `pars_site` происходит в обеих БД: основной (`pars_site_update_metadata_pg`) и зеркальной (`pars_site_update_vector`). Перед записью вектор конвертируется в строковый литерал вида `[0.1,0.2,...]`, чтобы гарантировать корректное приведение к `vector`.

## 3. Сравнение с ОКВЭД
* Основной ОКВЭД определяется по данным DaData и/или `get_okved_main_pg`. Дополнительные коды добавляются только для проверки.
* Для каждого кода строим embedding (кэшируется в `okved_vectors_cache`).
* Косинусное сходство считается общей функцией `cosine_similarity` из `vector_similarity.py` — она используется во всех сервисах, поэтому формула единая.
* Результат в ответе теперь показывает **только скор по основному ОКВЭДу**. Среднее по остальным кодам вычисляется для диагностики, но не влияет на ответ.
* Если embedding по основному ОКВЭДу не удалось получить, в ответ добавляется заметка `Не удалось вычислить скор по основному ОКВЭД` и для сортировки доменов используется среднее значение.

## 4. Ответ API
`ParseSiteResponse` возвращает расширенную структуру:

| Поле | Описание |
| --- | --- |
| `status` | `success` или `partial_success` — в зависимости от того, все ли домены обработаны. |
| `message` | Человеко-читаемая сводка (например, `Обработаны все домены (2 из 2)`). |
| `started_at` / `finished_at` | Таймстампы начала и окончания обработки в UTC. |
| `duration_seconds` / `duration_ms` | Продолжительность выполнения. |
| `domains_attempted` / `domains_succeeded` | Количество доменов в обработке и успешных доменов. |
| `failed_domains` | Список доменов, по которым возникли ошибки. |
| `results` | Детальные записи по каждому домену. |

Каждый элемент `ParsedSiteResult` дополняется полями:

* `description_status` — что произошло с описанием (например, «Описание и вектор получены»).
* `notes` — список пояснений: получен ли embedding, почему не удалось извлечь текст и т.д.
* `processing_ms` — время обработки конкретного домена (учитывает загрузку и пост-обработку).
* `okved_score` — скор по основному ОКВЭДу.
* `okved_score_avg` — диагностическое среднее по всем кодам (используется только при отсутствии главного скора).
* `okved_scores` — расшифровка скоринга по каждому коду.

## 5. Что важно помнить
* Все косинусные сравнения в проекте выполняются через единую функцию `cosine_similarity`.
* Вектор описания сайта сохраняется сразу в обе базы, поэтому `pars_site.text_vector` всегда содержит актуальный embedding при успешном анализе.
* При частичном успехе (не все домены распарсились) сервис всё равно возвращает сводку с перечнем неудачных доменов и общим временем работы.
