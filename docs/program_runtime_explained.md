# Полное объяснение работы программы (runtime walkthrough)

Документ описывает, что именно происходит внутри сервиса на уровне кода: от старта FastAPI до завершения полного пайплайна по ИНН.

## 1. Инициализация приложения

Точка входа — `app/main.py`.

### 1.1 Startup

При событии `startup` сервис:

1. Инициализирует подключения к БД через фабрики `get_*_engine()`.
2. Выполняет `ensure_parsing_schema()` для `parsing_data`.
3. Создаёт таблицы Bitrix-моделей (в частности `b24_companies_raw`) через `create_bitrix_tables(BaseBitrix)`.
4. При валидной конфигурации Bitrix (`B24_SYNC_ENABLED`, `B24_BASE_URL`, DSN) запускает фоновую задачу `run_b24_sync_loop(interval)`.
5. Логирует зарегистрированные роуты для быстрой диагностики.

Итог: после startup приложение уже может принимать запросы и, при необходимости, фоново синхронизировать Bitrix24.

### 1.2 Shutdown

При остановке сервис:

1. Отменяет фоновые asyncio‑таски.
2. Закрывает общий HTTP‑клиент analyze-json (`close_analyze_json_http_client`).
3. Закрывает все SQLAlchemy engines (`dispose`).

Это защищает от утечек соединений и «висящих» фоновых задач.

---

## 2. Основной пользовательский путь: `pipeline/full`

Главный сценарий реализован в `app/api/pipeline.py` (`POST /v1/pipeline/full`). Он собирает в один запрос все этапы обработки.

Порядок шагов:

### Шаг 1 — lookup_card

Вызывается `lookup_card_get(inn=...)` из `app/api/lookup.py`.

Что делает lookup:

1. Валидирует ИНН (цифры, непустое значение).
2. Пытается взять кэш `DaDataResult` из локальной БД.
3. Если кэша нет (или запрошен refresh) — идёт в DaData (`find_party_by_inn`).
4. Преобразует ответ DaData во внутреннюю структуру (`map_summary_from_dadata`).
5. Пишет результат в локальные таблицы (`replace_dadata_raw`, `upsert_company_summary`).
6. Формирует обогащённую карточку компании (`CompanyCard`) с производными полями:
   - `company_title`
   - `production_address_2024`
   - вторичные ОКВЭД `okved_vtor_*`
7. Синхронизирует/создаёт запись клиента в `clients_requests` (через слой parsing/parsing_mirror).

Зачем шаг нужен: гарантирует, что у pipeline есть валидная компания и базовый `client_request_id`.

### Шаг 2 — parse_site

Вызывается `run_parse_site(ParseSiteRequest(...))` из `app/services/parse_site.py`.

Что происходит внутри:

1. Собираются кандидаты доменов из:
   - входных параметров (`parse_domain`, `parse_domains`),
   - email‑доменов,
   - данных из БД (`domain_1`, `domain_2`, исторические значения).
2. Домены нормализуются, фильтруются мусорные и личные почтовые (`gmail.com`, `mail.ru` и т.д.).
3. Для каждого домена:
   - строится home URL,
   - запрашивается HTML через scraping‑слой,
   - текст режется на chunks,
   - chunks сохраняются в `pars_site`.
4. Для описания сайта и chunks запрашиваются embeddings и метаданные во внешнем analyze‑сервисе.
5. При отсутствии полезного контента с сайта включается fallback по ОКВЭД:
   - берётся ОКВЭД компании,
   - запрашивается `prodclass_by_okved`,
   - фиксируется причина fallback в ответе.
6. Возвращается `ParseSiteResponse` со статусом:
   - `success`
   - `partial_success`
   - `fallback`

Зачем шаг нужен: готовит текстовую и векторную базу, на которой работают downstream‑алгоритмы.

### Шаг 3 — analyze_json

Вызывается `analyze_from_inn_get(...)` из `app/api/analyze_json.py`.

Внутренний процесс:

1. Берётся актуальный `pars_site` снапшот для компании.
2. Дополняется каталогами товаров/оборудования из БД.
3. Формируется payload во внешний AI‑сервис анализа.
4. Выполняется запрос, валидируется и нормализуется ответ.
5. Применяется `db_payload`: результат раскладывается по таблицам `ai_site_*`.
6. Для отладки сохраняются санитизированные версии больших payload (без тяжёлых полей и длинных текстов).
7. При необходимости автоматически создаются отсутствующие таблицы/колонки (например, `ai_site_openai_responses`).

Зачем шаг нужен: превращает «сырой текст сайта» в структурированные AI‑данные (товары, оборудование, классы, описания).

### Шаг 4 — ib_match

Вызывается `ib_match_by_inn_get(...)` из `app/api/routes.py`, далее логика в `app/services/ib_match.py`.

Что делает:

1. Находит `client_id` по ИНН.
2. Берёт `text_vector` из `pars_site`.
3. Считает косинусную близость (`cosine_similarity`) к справочнику `ib_prodclass`.
4. Сохраняет лучшие соответствия и использует их как источник для следующего шага.

Зачем шаг нужен: даёт формальный «продуктовый класс» компании, привязанный к внутренним каталогам.

### Шаг 5 — equipment_selection

Вызывается `get_equipment_selection_by_inn(...)` через `app/api/routes.py`, основная логика в `app/services/equipment_selection.py`.

Что делает:

1. Определяет актуальный `client_request_id` по ИНН.
2. Выбирает стратегию источника:
   - по данным сайта (если качество/скор достаточные),
   - fallback по ОКВЭД (если сайт слабый или недоступный).
3. Подтягивает данные из AI‑таблиц и IB‑соответствий.
4. Формирует итоговые записи в `EQUIPMENT_*` и возвращает результат API.

Зачем шаг нужен: это «финальная бизнес‑цель» пайплайна — получить готовый подбор оборудования.

---

## 3. Обработка ошибок и устойчивость

В `pipeline/full` каждый шаг выполняется через общий `_run_step(...)`:

- `HTTPException` перехватываются и добавляются в `errors` с кодом и текстом;
- неожиданные исключения тоже логируются и попадают в `errors`;
- только `lookup_card` считается фатальным шагом (если падает — pipeline не продолжает выполнение).

Это позволяет возвращать частичный результат вместо полного падения всего процесса.

---

## 4. Автоматический пакетный режим: `pipeline/auto`

`POST /v1/pipeline/auto`:

1. Берёт до 200 последних ИНН из `DaDataResult`.
2. Для каждого ИНН проверяет наличие артефактов:
   - `clients_requests`,
   - `pars_site`,
   - `ai_site_goods_types`,
   - `ai_site_equipment`,
   - `EQUIPMENT_ALL`.
3. Выбирает только ИНН без `equipment_selection`.
4. Запускает до 5 полных пайплайнов подряд.
5. Возвращает:
   - `processed` (что обработано сейчас),
   - `skipped` (что осталось вне лимита).

Это режим для «догоняющей» фоновой обработки.

---

## 5. Почему в сервисе много БД и mirror‑слоёв

Часть функций работает сразу с несколькими контурами (`bitrix_data`, `parsing_data`, `postgres`) и имеет mirror‑операции. Это сделано, чтобы:

- сохранить совместимость со старыми потребителями данных;
- дать постепенную миграцию между витринами/схемами;
- не блокировать всю систему при частичной недоступности одного контура.

Именно поэтому многие шаги проверяют доступность конкретной БД и умеют работать деградированно.

---

## 6. Что смотреть при диагностике проблем

1. `GET /health` — состояние БД.
2. `GET /v1/analyze-service/health` — доступность внешнего AI сервиса.
3. Логи `api.pipeline`, `api.analyze-json`, `services.parse_site`.
4. Наличие свежих данных в:
   - `clients_requests`,
   - `pars_site`,
   - `ai_site_*`,
   - `EQUIPMENT_*`.

Если `parse_site` вернул `fallback`, это обычно означает, что сайт не дал пригодного текста, и дальнейшие шаги перешли в стратегию по ОКВЭД.

