# Детальный разбор AI-анализа организации: с очередью и без очереди

Документ описывает **фактический backend-flow** в этом репозитории и разводит два режима:

1. **С очередью (наблюдаемый queue-state)** — когда запись уже создана в `clients_requests`, но фактический запуск ещё не начался (`created_at` есть, `started_at` ещё нет).
2. **Без очереди (синхронный запуск)** — когда API вызывает шаги сразу в текущем HTTP-запросе (`/v1/pipeline/full` или `/v1/analyze-json/{inn}`), без внешнего брокера задач.

---

## 0) Какие сущности участвуют в AI-анализе

Основной слой данных и интеграций:

- `public.clients_requests` — «карточка запуска»: кто анализируется, тайминг (`created_at`, `started_at`, `ended_at`), длительность (`sec_duration`) и флаги шагов `step_1..step_12`.
- `public.pars_site` — распарсенные тексты сайта (`text_par`), URL/домен, `company_id`.
- `public.ai_site_prodclass`, `public.ai_site_goods_types`, `public.ai_site_equipment` — результаты AI-классификации и матчей.
- внешний AI-сервис (`ANALYZE_BASE`) — вызывается через HTTP из `analyze_json`/`analyze_client`.
- Bitrix-слой (`DaDataResult`) — источник списка компаний и fallback по некоторым атрибутам.

Практически это означает: **сначала должны существовать клиент и данные сайта**, затем вызывается внешний AI, потом результаты сохраняются обратно в Postgres и агрегируются в endpoint-ах.

---

## 1) Как определяется состояние анализа (queued/running/completed/failed/stopped)

Состояние строится в `GET /api/ai-analysis/companies` по последней записи `clients_requests` на каждый ИНН:

1. Выбирается «последний запуск» по `COALESCE(ended_at, started_at, created_at)` + `id`.
2. Если есть `ended_at` и `step_12=true` → `completed`.
3. Если есть `ended_at`, но финальный шаг не выставлен, и при этом был старт/шаги → `failed`.
4. Если есть `started_at` (или хотя бы один step=true), но нет `ended_at` → `running`.
5. Если `created_at` есть, но старта нет → `queued`.
6. Если записи нет или тайминги пустые → `stopped`.

Дополнительно:

- Прогресс считается как доля выставленных `step_1..step_12`.
- Для `queued` прогресс = `0.0`.
- Для `queued` длительность принудительно не растёт (0), пока запуск реально не начался.

Это «контракт наблюдаемого состояния», который UI использует для таймера и прогресс-бара.

---

## 2) Режим «с очередью»: что именно происходит

> В текущей реализации это **DB-очередь по состояниям**, а не отдельный брокер (Rabbit/Kafka/Celery).

### Шаг 2.1. Постановка в очередь (queue-visible)

Обычно цепочка начинается с `lookup`/создания (или обновления) `clients_requests`:

- для ИНН создаётся/обновляется запись с базовыми полями компании;
- `created_at` уже есть (по умолчанию в таблице), поэтому в статусном API компания становится `queued`, если `started_at` ещё пуст;
- при lookup может быть запланирован фоновой `parse_site` (через `schedule_parse_site_background`) — это отдельный фоновой триггер.

### Шаг 2.2. Ожидание в очереди

Пока запуск не начался:

- статус = `queued`;
- `analysis_duration_ms` остаётся 0;
- прогресс 0.0.

UI в этот момент показывает, что задача в очереди, но не исполняется.

### Шаг 2.3. Переход к выполнению (running)

Как только кто-то запускает фактический анализ (например, pipeline/full или auto-проход), начинает заполняться шаговый прогресс и/или `started_at`.

С этого момента:

- статус становится `running`;
- длительность начинает считаться от `started_at` (или fallback от `created_at`, если старт не проставился);
- прогресс = число выполненных step / 12.

### Шаг 2.4. Завершение

- `ended_at + step_12=true` → `completed`;
- `ended_at` без финального шага → `failed`;
- длительность фиксируется как `max(sec_duration*1000, timeline)`.

### Шаг 2.5. Что если данных не хватает

- Нет записи `clients_requests` по ИНН: статусное API вернёт `stopped`.
- Есть запись, но не стартовали шаги: остаётся `queued`.
- Если parsing-DB не сконфигурирована: `GET /api/ai-analysis/companies` вернёт `503`.

---

## 3) Режим «без очереди» (синхронный запрос): полный runtime-путь

Это когда клиент вызывает API, и всё делается сразу в рамках текущего запроса.

### Вариант A: `/v1/pipeline/full`

Пайплайн выполняется последовательно:

1. `lookup_card` — тянет/обновляет карточку компании.
2. `parse_site` — собирает сайт, текст и сохраняет в `pars_site`.
3. `analyze_json` — отправляет текст и каталоги во внешний AI.
4. `ib_match` — дообогащает соответствия по embedding/справочникам.
5. `equipment_selection` — рассчитывает оборудование.

Ошибки по шагам собираются в `errors`; фатальным в этой реализации считается только `lookup_card`, остальные шаги могут не остановить весь ответ.

### Вариант B: `/v1/analyze-json/{inn}` напрямую

Если вызывается только analyze-json:

1. Валидируется ИНН и конфиг (`ANALYZE_BASE`, Postgres DSN).
2. (Опционально) `refresh_site=true` → предварительный запуск `parse_site`.
3. Из `clients_requests` и `pars_site` собираются последние снапшоты текста по доменам.
4. Текст чистится (контрольные символы/пробелы/пустой текст).
5. (Опционально) подгружаются каталоги `ib_goods_types`/`ib_equipment`.
6. Формируется JSON и отправляется во внешний AI по URL `ANALYZE_BASE`.
7. Ответ парсится; обязателен `db_payload`.
8. В транзакции обновляются `pars_site.description/text_vector`, затем перезаписываются `ai_site_prodclass`, `ai_site_goods_types`, `ai_site_equipment`.
9. Возвращается агрегированный ответ с деталями по каждому домену (`runs`).

---

## 4) Куда именно ходим (внешние и внутренние обращения)

### Внутренние БД

- `bitrix_data` (через `DaDataResult`) — список компаний/названия.
- `postgres/parsing_data` — `clients_requests`, `pars_site`, `ai_site_*`, справочники.

### Внешние HTTP

- `ANALYZE_BASE`:
  - `/v1/analyze/json` — основной анализ текста сайта;
  - `/v1/site-profile` — генерация описания + vector;
  - `/ai-search` — embedding;
  - `/v1/prompts/site-unavailable` — fallback-классификация по ОКВЭД.

Для внешних вызовов есть health-check и retry-поведение (`_post_with_retries`, до 3 попыток с backoff).

---

## 5) Что ищем на каждом шаге

### На стороне БД

- Последний `clients_requests` по ИНН (базовая связка запуска).
- Связанные записи `pars_site` по `company_id` и домену.
- AI-результаты по `text_pars_id`/`company_id`.
- Справочники (`ib_prodclass`, `ib_goods_types`, `ib_equipment`, отраслевые таблицы).

### На стороне AI

- Классификацию продкласса/товаров/оборудования.
- Скоринги (`prodclass_score`, `description_score`, `okved_score`, `description_okved_score`).
- Текстовое описание и вектор.

---

## 6) Fallback-логика: что делаем, если что-то не найдено

### Нет БД/конфига

- Нет Postgres DSN для pipeline/analyze-json → `503`.
- Нет `ANALYZE_BASE` → `400/503` в зависимости от точки входа.

### Нет данных сайта

- Можно принудительно `refresh_site=true`.
- Если после нормализации текст пуст — запрос отклоняется (не отправляем мусор внешнему AI).

### Нет каталогов/справочников

- analyze-json продолжает работу с пустыми каталогами (warning в логах).
- ai-analyzer пытается определить названия через альтернативные таблицы/колонки; если не нашёл — оставляет fallback label (например, `Prodclass {id}`).

### Внешний AI недоступен

- health-check + retry на HTTP уровне;
- при неуспехе возвращается ошибка уровня API (`502/503`) с диагностикой;
- для сценариев без сайта возможен fallback «классификация по ОКВЭД» через специальный prompt endpoint.

### Неполный `db_payload`

- отсутствие обязательного `db_payload` трактуется как нарушение контракта внешнего сервиса и приводит к ошибке.

---

## 7) Как работает «анализ в очереди» в auto-режиме

`/v1/pipeline/auto` — это «очередь кандидатов» без брокера:

1. Берутся до 200 свежих ИНН из `DaDataResult`.
2. Для каждого ищется последний `clients_requests.id`.
3. Проверяется, есть ли уже `pars_site`, `ai_goods`, `ai_equipment`, `equipment_selection`.
4. В обработку идут те, у кого ещё нет `equipment_selection`.
5. За один запуск обрабатываются первые 5 (`_AUTO_PROCESS_LIMIT`).
6. Для каждого вызывается тот же `run_full_pipeline`.

Итого: queue здесь — это **выборка pending-кандидатов + лимитированная пакетная обработка**.

---

## 8) Краткое различие «с очередью» vs «без очереди»

- **С очередью:** сначала фиксируем задачу в `clients_requests` (`created_at`), UI видит `queued`, фактический запуск может произойти позже; прогресс и длительность появляются после старта.
- **Без очереди:** клиент сразу вызывает endpoint и получает результат текущего исполнения; ожидание в очереди как отдельная фаза отсутствует.
- **Технически:** обе модели используют одни и те же таблицы и шаги, но различается момент старта выполнения и способ оркестрации (polling состояния vs immediate run).

